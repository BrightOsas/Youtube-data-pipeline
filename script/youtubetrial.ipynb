{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import googleapiclient.discovery\n",
    "from datetime import datetime\n",
    "from googleapiclient.errors import HttpError\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyBHCUXaE1ZN33zfnxlbJFic0Z76UY_WqMU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Your script's main code here\n",
    "    api_key = input(\"API key: \")\n",
    "    youtube = googleapiclient.discovery.build('youtube', 'v3', developerKey = api_key)\n",
    "    def get_date_input(prompt):\n",
    "        while True:\n",
    "            try:\n",
    "                date_str = input(prompt)\n",
    "                date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                return date_obj\n",
    "            except ValueError:\n",
    "                print(\"Invalid date format. Please use YYYY-MM-DD.\")\n",
    "    start_date = get_date_input(\"Enter the start date (YYYY-MM-DD): \").strftime('%Y-%m-%dT00:00:00Z')\n",
    "    end_date = get_date_input(\"Enter the end date (YYYY-MM-DD): \").strftime('%Y-%m-%dT23:59:59Z')\n",
    "    all_video_ids = []\n",
    "    max_results_per_page = 50\n",
    "    video_search_data_list = []\n",
    "    video_stats_data_list = []\n",
    "    channel_data_list = []\n",
    "\n",
    "    try:\n",
    "        next_page_token = None\n",
    "\n",
    "        while True:\n",
    "            # Execute the YouTube API search with the date range filter and pagination\n",
    "            sports = youtube.search().list(\n",
    "                part='id',\n",
    "                type='video',\n",
    "                q='sport,sports',\n",
    "                order='relevance',\n",
    "                maxResults=max_results_per_page,\n",
    "                publishedAfter=start_date,\n",
    "                publishedBefore=end_date,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract video IDs from the current page and add them to the list\n",
    "            for item in sports.get('items', []):\n",
    "                video_id = item['id']['videoId']\n",
    "                all_video_ids.append(video_id)\n",
    "\n",
    "            # Check if there are more pages of results\n",
    "            next_page_token = sports.get('nextPageToken')\n",
    "\n",
    "            # Exit the loop if there are no more pages\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    try:\n",
    "        for video_id in all_video_ids:\n",
    "            video_response = youtube.videos().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            # Extract the video details (search data)\n",
    "            video_details = video_response.get('items', [])[0]['snippet']\n",
    "            video_content_details = video_response.get('items', [])[0]['contentDetails']\n",
    "            video_statistics = video_response.get('items', [])[0]['statistics']\n",
    "\n",
    "            # Extract the channelId for the video\n",
    "            channel_id = video_details['channelId']\n",
    "\n",
    "            # Execute another request to retrieve channel details\n",
    "            channel_response = youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channel_id\n",
    "            ).execute()\n",
    "\n",
    "            channel_details = channel_response.get('items', [])[0]['snippet']\n",
    "\n",
    "            # Append data to respective lists\n",
    "            video_search_data_list.append({\n",
    "                'videoid': video_id,\n",
    "                'publishedAt': video_details['publishedAt'],\n",
    "                'channelid': video_details['channelId'],\n",
    "                'title': video_details['title'],\n",
    "                'description': video_details['description'],\n",
    "                'locationdescription': video_content_details.get('locationDescription', ''),\n",
    "                'topiccategories': video_details.get('topicCategories', []),\n",
    "                'duration': video_content_details.get('duration', '')\n",
    "            })\n",
    "\n",
    "            video_stats_data_list.append({\n",
    "                'videoid': video_id,\n",
    "                'viewcounts': video_statistics.get('viewCount', 0),\n",
    "                'likecounts': video_statistics.get('likeCount', 0),\n",
    "                'favouritecounts': video_statistics.get('favoriteCount', 0),\n",
    "                'commentcounts': video_statistics.get('commentCount', 0)\n",
    "            })\n",
    "\n",
    "            channel_data_list.append({\n",
    "                'channelid': channel_id,\n",
    "                'videoid': video_id,\n",
    "                'title': channel_details['title'],\n",
    "                'description': channel_details['description'],\n",
    "                'country': channel_details.get('country', ''),\n",
    "                'customurl': channel_details.get('customUrl', ''),\n",
    "                'defaultlanguage': channel_details.get('defaultLanguage', '')\n",
    "            })\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Total video IDs: {len(all_video_ids)}\")   \n",
    "    print(f\"Total search(videoids) processed: {len(video_search_data_list)}\")\n",
    "    print(f\"Total stats(videoids) processed: {len(video_stats_data_list)}\")\n",
    "    print(f\"Total channels(videoids) processed: {len(channel_data_list)}\")\n",
    "\n",
    "    # Create DataFrames\n",
    "    video_search_df = pd.DataFrame(video_search_data_list)\n",
    "    video_stats_df = pd.DataFrame(video_stats_data_list)\n",
    "    channel_df = pd.DataFrame(channel_data_list)\n",
    "\n",
    "    video_search_df.to_csv('video_search_data1.csv', index=False)\n",
    "    video_stats_df.to_csv('video_stats_data1.csv', index=False)\n",
    "    channel_df.to_csv('channel_data1.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
